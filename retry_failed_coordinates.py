#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ–°è½¬æ¢å¤±è´¥çš„åæ ‡ç‚¹ - ä¸´æ—¶è„šæœ¬

åŠŸèƒ½è¯´æ˜ï¼š
1. ä» transformed_data.csv ä¸­æ‰¾å‡ºè½¬æ¢å¤±è´¥çš„åæ ‡ï¼ˆlongitude/latitude ä¸ºç©ºï¼‰
2. ä½¿ç”¨æ–°çš„ API KEY é‡æ–°æ‰¹é‡è½¬æ¢
3. å°†æˆåŠŸè½¬æ¢çš„ç»“æœæ›´æ–°å›åŸ CSV æ–‡ä»¶

ä½¿ç”¨æ–¹æ³•ï¼š
1. åœ¨ .env æ–‡ä»¶ä¸­æ›´æ–° MAPTILER_API_KEY
2. è¿è¡Œ: python retry_failed_coordinates.py

ä½œè€…: Claude Code
æ—¥æœŸ: 2025-11-11
"""

import pandas as pd
import asyncio
import aiohttp
import os
from typing import Tuple, Optional, List, Dict
from pathlib import Path
import logging
from dotenv import load_dotenv
from collections import defaultdict

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class APIKeyManager:
    """API å¯†é’¥ç®¡ç†å™¨ - æ”¯æŒå¤šä¸ª API KEY å¹¶è‡ªåŠ¨åˆ‡æ¢"""

    def __init__(self, api_keys: List[str]):
        """
        åˆå§‹åŒ– API å¯†é’¥ç®¡ç†å™¨

        å‚æ•°:
            api_keys: API å¯†é’¥åˆ—è¡¨
        """
        if not api_keys:
            raise ValueError("è‡³å°‘éœ€è¦æä¾›ä¸€ä¸ª API KEY")

        self.api_keys = api_keys
        self.current_index = 0
        self.stats = defaultdict(lambda: {
            'requests': 0,
            'success': 0,
            'rate_limit': 0,
            'errors': 0
        })
        logger.info(f"âœ… å·²åŠ è½½ {len(api_keys)} ä¸ª API KEY")

    def get_current_key(self) -> str:
        """è·å–å½“å‰ä½¿ç”¨çš„ API KEY"""
        return self.api_keys[self.current_index]

    def switch_to_next_key(self) -> bool:
        """
        åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª API KEY

        è¿”å›:
            æ˜¯å¦æˆåŠŸåˆ‡æ¢ï¼ˆFalse è¡¨ç¤ºå·²ç»æ˜¯æœ€åä¸€ä¸ª KEYï¼‰
        """
        if self.current_index < len(self.api_keys) - 1:
            old_index = self.current_index
            self.current_index += 1
            logger.warning(f"ğŸ”„ åˆ‡æ¢ API KEY: [{old_index}] -> [{self.current_index}]")
            return True
        else:
            logger.error(f"âš ï¸ æ‰€æœ‰ {len(self.api_keys)} ä¸ª API KEY éƒ½å·²è¾¾åˆ°é€Ÿç‡é™åˆ¶!")
            return False

    def record_request(self, key: str):
        """è®°å½•è¯·æ±‚"""
        self.stats[key]['requests'] += 1

    def record_success(self, key: str):
        """è®°å½•æˆåŠŸ"""
        self.stats[key]['success'] += 1

    def record_rate_limit(self, key: str):
        """è®°å½•é€Ÿç‡é™åˆ¶"""
        self.stats[key]['rate_limit'] += 1

    def record_error(self, key: str):
        """è®°å½•é”™è¯¯"""
        self.stats[key]['errors'] += 1

    def print_stats(self):
        """æ‰“å°ä½¿ç”¨ç»Ÿè®¡"""
        logger.info("\n=== ğŸ“Š API KEY ä½¿ç”¨ç»Ÿè®¡ ===")
        for idx, key in enumerate(self.api_keys):
            stats = self.stats[key]
            key_preview = f"{key[:10]}...{key[-4:]}" if len(key) > 14 else key
            logger.info(f"KEY [{idx}] ({key_preview}):")
            logger.info(f"  æ€»è¯·æ±‚: {stats['requests']}")
            logger.info(f"  æˆåŠŸ: {stats['success']}")
            logger.info(f"  é€Ÿç‡é™åˆ¶: {stats['rate_limit']}")
            logger.info(f"  å…¶ä»–é”™è¯¯: {stats['errors']}")


class AsyncCoordinateTransformer:
    """å¼‚æ­¥åæ ‡è½¬æ¢å™¨ç±» - ä½¿ç”¨ MapTiler API è¿›è¡Œåæ ‡ç³»è½¬æ¢"""

    # MapTiler API é…ç½®
    API_BASE_URL = "https://api.maptiler.com/coordinates/transform"
    SOURCE_CRS = 27700  # è‹±å›½å›½å®¶ç½‘æ ¼åæ ‡ç³» EPSGä»£ç 
    TARGET_CRS = 4326   # WGS84 ç»çº¬åº¦åæ ‡ç³» EPSGä»£ç 

    def __init__(self, api_key_manager: APIKeyManager, max_concurrent: int = 10):
        """
        åˆå§‹åŒ–å¼‚æ­¥åæ ‡è½¬æ¢å™¨

        å‚æ•°:
            api_key_manager: API å¯†é’¥ç®¡ç†å™¨
            max_concurrent: æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
        """
        self.api_key_manager = api_key_manager
        self.max_concurrent = max_concurrent
        self.request_count = 0
        self.failed_requests = 0
        self.successful_requests = 0
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.rate_limit_backoff = 1.0  # é€Ÿç‡é™åˆ¶é€€é¿æ—¶é—´ï¼ˆç§’ï¼‰

    async def transform_coordinate(
        self,
        session: aiohttp.ClientSession,
        x: float,
        y: float,
        max_retries: int = 3
    ) -> Tuple[Tuple[float, float], Optional[Tuple[float, float]]]:
        """
        å¼‚æ­¥è½¬æ¢å•ä¸ªåæ ‡ç‚¹ï¼Œæ”¯æŒ API KEY è‡ªåŠ¨åˆ‡æ¢

        å‚æ•°:
            session: aiohttp ä¼šè¯å¯¹è±¡
            x: ä¸œå‘åæ ‡ (Easting)
            y: åŒ—å‘åæ ‡ (Northing)
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé‡åˆ° 429 é”™è¯¯æ—¶ï¼‰

        è¿”å›:
            ((x, y), (lon, lat)) å…ƒç»„ï¼Œå¤±è´¥åˆ™è¿”å› ((x, y), None)
        """
        async with self.semaphore:  # é™åˆ¶å¹¶å‘æ•°
            for retry in range(max_retries):
                try:
                    # è·å–å½“å‰ API KEY
                    current_key = self.api_key_manager.get_current_key()

                    # æ„å»º API è¯·æ±‚ URL
                    url = f"{self.API_BASE_URL}/{x},{y}.json"
                    params = {
                        's_srs': self.SOURCE_CRS,
                        't_srs': self.TARGET_CRS,
                        'key': current_key
                    }

                    # å‘é€å¼‚æ­¥è¯·æ±‚
                    async with session.get(url, params=params, timeout=aiohttp.ClientTimeout(total=10)) as response:
                        self.request_count += 1
                        self.api_key_manager.record_request(current_key)

                        if response.status == 200:
                            data = await response.json()
                            # API è¿”å›æ ¼å¼: {"results": [{"x": lon, "y": lat}]}
                            if 'results' in data and len(data['results']) > 0:
                                result = data['results'][0]
                                lon = result['x']
                                lat = result['y']
                                self.successful_requests += 1
                                self.api_key_manager.record_success(current_key)
                                logger.debug(f"âœ“ ({x}, {y}) -> ({lon:.6f}, {lat:.6f})")
                                return ((x, y), (lon, lat))
                            else:
                                logger.warning(f"âš  Invalid API response for ({x}, {y})")
                                self.api_key_manager.record_error(current_key)
                                self.failed_requests += 1
                                return ((x, y), None)

                        elif response.status == 429:
                            # é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥
                            self.api_key_manager.record_rate_limit(current_key)

                            # é¦–æ¬¡æˆ–å‰å‡ æ¬¡é‡è¯•ï¼šç­‰å¾…åé‡è¯•ï¼ˆä¸åˆ‡æ¢ KEYï¼‰
                            if retry < max_retries - 1:
                                wait_time = self.rate_limit_backoff * (2 ** retry)  # æŒ‡æ•°é€€é¿
                                logger.warning(f"âš  é€Ÿç‡é™åˆ¶ (429) for ({x}, {y})ï¼Œç­‰å¾… {wait_time:.1f}s åé‡è¯• ({retry + 1}/{max_retries})")
                                await asyncio.sleep(wait_time)
                                continue  # é‡è¯•è¯·æ±‚
                            else:
                                # å¤šæ¬¡é‡è¯•åä»ç„¶ 429ï¼Œå°è¯•åˆ‡æ¢ API KEY
                                logger.warning(f"âš  æŒç»­é€Ÿç‡é™åˆ¶ (429) for ({x}, {y})ï¼Œå°è¯•åˆ‡æ¢ API KEY")
                                if self.api_key_manager.switch_to_next_key():
                                    logger.info(f"ğŸ”„ åˆ‡æ¢åˆ°æ–°çš„ API KEY å¹¶é‡è¯•åæ ‡ ({x}, {y})")
                                    await asyncio.sleep(1.0)  # åˆ‡æ¢åç­‰å¾…
                                    continue  # é‡è¯•è¯·æ±‚
                                else:
                                    # æ‰€æœ‰ API KEY éƒ½å·²è¾¾åˆ°é™åˆ¶
                                    logger.error(f"âŒ æ‰€æœ‰ API KEY éƒ½å·²è¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼Œåæ ‡ ({x}, {y}) è½¬æ¢å¤±è´¥")
                                    self.failed_requests += 1
                                    return ((x, y), None)

                        else:
                            logger.error(f"âœ— API status {response.status} for ({x}, {y})")
                            self.api_key_manager.record_error(current_key)
                            self.failed_requests += 1
                            return ((x, y), None)

                except asyncio.TimeoutError:
                    logger.error(f"â± Timeout for ({x}, {y})")
                    current_key = self.api_key_manager.get_current_key()
                    self.api_key_manager.record_error(current_key)
                    self.failed_requests += 1
                    return ((x, y), None)
                except Exception as e:
                    logger.error(f"âŒ Error for ({x}, {y}): {str(e)}")
                    current_key = self.api_key_manager.get_current_key()
                    self.api_key_manager.record_error(current_key)
                    self.failed_requests += 1
                    return ((x, y), None)

            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
            return ((x, y), None)

    async def transform_batch(
        self,
        coordinates_list: List[Tuple[float, float]]
    ) -> Dict[Tuple[float, float], Tuple[float, float]]:
        """
        å¼‚æ­¥æ‰¹é‡è½¬æ¢åæ ‡

        å‚æ•°:
            coordinates_list: åæ ‡åˆ—è¡¨ [(x1, y1), (x2, y2), ...]

        è¿”å›:
            åæ ‡æ˜ å°„å­—å…¸ {(x, y): (lon, lat), ...}
        """
        total = len(coordinates_list)
        logger.info(f"ğŸš€ å¼€å§‹å¼‚æ­¥æ‰¹é‡è½¬æ¢ {total} ä¸ªåæ ‡ç‚¹ (å¹¶å‘æ•°: {self.max_concurrent})...")

        # åˆ›å»ºå¼‚æ­¥ HTTP ä¼šè¯
        async with aiohttp.ClientSession() as session:
            # åˆ›å»ºæ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
            tasks = [
                self.transform_coordinate(session, x, y)
                for x, y in coordinates_list
            ]

            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡å¹¶æ˜¾ç¤ºè¿›åº¦
            results = []
            batch_size = 100
            for i in range(0, len(tasks), batch_size):
                batch = tasks[i:i + batch_size]
                batch_results = await asyncio.gather(*batch)
                results.extend(batch_results)

                # æ˜¾ç¤ºè¿›åº¦
                progress = min(i + batch_size, total)
                logger.info(f"ğŸ“Š è¿›åº¦: {progress}/{total} ({progress/total*100:.1f}%)")

        # æ„å»ºåæ ‡æ˜ å°„å­—å…¸
        coord_map = {}
        for (x, y), result in results:
            if result:
                coord_map[(x, y)] = result

        success_count = len(coord_map)
        success_rate = success_count / total * 100 if total > 0 else 0
        logger.info(f"âœ… æ‰¹é‡è½¬æ¢å®Œæˆ!")
        logger.info(f"   æˆåŠŸ: {self.successful_requests}/{total} ({success_rate:.2f}%)")
        logger.info(f"   å¤±è´¥: {self.failed_requests}")

        # æ‰“å° API KEY ä½¿ç”¨ç»Ÿè®¡
        self.api_key_manager.print_stats()

        return coord_map


async def retry_failed_coordinates():
    """
    é‡æ–°è½¬æ¢å¤±è´¥çš„åæ ‡ç‚¹ä¸»å‡½æ•°
    """
    # ========== é…ç½®å‚æ•° ==========
    project_root = Path(__file__).parent
    DATA_FILE = project_root / 'data/transformed_data.csv'

    # ä»ç¯å¢ƒå˜é‡è¯»å– API å¯†é’¥ï¼ˆæ”¯æŒå¤šä¸ª KEYï¼Œç”¨é€—å·åˆ†éš”ï¼‰
    maptiler_api_key_str = os.getenv('MAPTILER_API_KEY', '')

    # è§£æ API KEY åˆ—è¡¨
    api_keys = []
    if maptiler_api_key_str:
        # æŒ‰é€—å·åˆ†éš”ï¼Œå¹¶å»é™¤ç©ºæ ¼
        api_keys = [key.strip() for key in maptiler_api_key_str.split(',') if key.strip()]

    if not api_keys:
        logger.error("âŒ é”™è¯¯: æœªæ‰¾åˆ° MAPTILER_API_KEY ç¯å¢ƒå˜é‡")
        logger.info("ğŸ’¡ è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æ–°çš„ MAPTILER_API_KEY")
        logger.info("ğŸ’¡ æ”¯æŒå¤šä¸ª API KEYï¼ˆç”¨é€—å·åˆ†éš”ï¼‰: KEY1,KEY2,KEY3")
        return

    # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
    MAX_CONCURRENT = 10

    logger.info("=" * 60)
    logger.info("ğŸ”„ å¼€å§‹é‡æ–°è½¬æ¢å¤±è´¥çš„åæ ‡ç‚¹")
    logger.info("=" * 60)

    # ========== ç¬¬ä¸€æ­¥ï¼šè¯»å–æ•°æ®å¹¶æ‰¾å‡ºå¤±è´¥çš„åæ ‡ ==========
    logger.info(f"ğŸ“‚ æ­£åœ¨è¯»å–æ–‡ä»¶: {DATA_FILE}")
    df = pd.read_csv(DATA_FILE, low_memory=False)
    logger.info(f"âœ“ å…±è¯»å– {len(df)} æ¡è®°å½•")

    # æ‰¾å‡ºè½¬æ¢å¤±è´¥çš„è®°å½•ï¼ˆlongitude æˆ– latitude ä¸ºç©ºï¼‰
    failed_mask = df['longitude'].isna() | df['latitude'].isna()
    failed_df = df[failed_mask]
    failed_count = len(failed_df)

    if failed_count == 0:
        logger.info("âœ… æ²¡æœ‰å¤±è´¥çš„åæ ‡éœ€è¦é‡æ–°è½¬æ¢!")
        return

    logger.info(f"ğŸ” å‘ç° {failed_count} æ¡è®°å½•éœ€è¦é‡æ–°è½¬æ¢")

    # æå–å”¯ä¸€çš„å¤±è´¥åæ ‡ç‚¹
    unique_failed_coords = failed_df[['x', 'y']].drop_duplicates()
    unique_count = len(unique_failed_coords)
    logger.info(f"ğŸ¯ å…±æœ‰ {unique_count} ä¸ªå”¯ä¸€çš„å¤±è´¥åæ ‡ç‚¹")

    # ========== ç¬¬äºŒæ­¥ï¼šé‡æ–°è½¬æ¢å¤±è´¥çš„åæ ‡ ==========
    logger.info("ğŸŒ å¼€å§‹é‡æ–°è½¬æ¢åæ ‡ç³» (EPSG:27700 -> EPSG:4326)...")

    # åˆ›å»º API å¯†é’¥ç®¡ç†å™¨
    api_key_manager = APIKeyManager(api_keys)

    # åˆå§‹åŒ–å¼‚æ­¥åæ ‡è½¬æ¢å™¨
    transformer = AsyncCoordinateTransformer(api_key_manager, max_concurrent=MAX_CONCURRENT)

    # å¼‚æ­¥æ‰¹é‡è½¬æ¢
    coords_list = [(row['x'], row['y']) for _, row in unique_failed_coords.iterrows()]
    coord_map = await transformer.transform_batch(coords_list)

    if not coord_map:
        logger.warning("âš  æ²¡æœ‰åæ ‡è½¬æ¢æˆåŠŸï¼Œæ— éœ€æ›´æ–°æ–‡ä»¶")
        return

    # ========== ç¬¬ä¸‰æ­¥ï¼šæ›´æ–°åŸæ•°æ® ==========
    logger.info("ğŸ“ æ­£åœ¨æ›´æ–°åæ ‡è½¬æ¢ç»“æœ...")

    updated_count = 0
    for idx, row in df.iterrows():
        # åªæ›´æ–°ä¹‹å‰å¤±è´¥çš„è®°å½•
        if pd.isna(row['longitude']) or pd.isna(row['latitude']):
            key = (row['x'], row['y'])
            if key in coord_map:
                lon, lat = coord_map[key]
                df.at[idx, 'longitude'] = lon
                df.at[idx, 'latitude'] = lat
                updated_count += 1

    logger.info(f"âœ… æˆåŠŸæ›´æ–° {updated_count} æ¡è®°å½•")

    # ========== ç¬¬å››æ­¥ï¼šä¿å­˜æ›´æ–°åçš„æ–‡ä»¶ ==========
    logger.info(f"ğŸ’¾ æ­£åœ¨ä¿å­˜æ›´æ–°åçš„æ•°æ®åˆ°: {DATA_FILE}")
    df.to_csv(DATA_FILE, index=False)
    logger.info("âœ… æ–‡ä»¶ä¿å­˜æˆåŠŸ!")

    # ========== ç¬¬äº”æ­¥ï¼šæ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ ==========
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š æœ€ç»ˆç»Ÿè®¡")
    logger.info("=" * 60)

    # ç»Ÿè®¡å½“å‰æˆåŠŸç‡
    total_records = len(df)
    successful_records = df['longitude'].notna().sum()
    success_rate = successful_records / total_records * 100

    logger.info(f"æ€»è®°å½•æ•°: {total_records}")
    logger.info(f"æˆåŠŸè½¬æ¢: {successful_records} ({success_rate:.2f}%)")
    logger.info(f"ä»ç„¶å¤±è´¥: {total_records - successful_records}")

    # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
    logger.info("\n=== ğŸ“Š æ›´æ–°åçš„æ•°æ®é¢„è§ˆ ===")
    print(df.head(10))

    logger.info("\n" + "=" * 60)
    logger.info("âœ… é‡æ–°è½¬æ¢ä»»åŠ¡å®Œæˆ!")
    logger.info("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    try:
        asyncio.run(retry_failed_coordinates())
    except Exception as e:
        logger.error(f"\nâŒ è½¬æ¢å¤±è´¥: {str(e)}")
        raise


if __name__ == '__main__':
    main()
