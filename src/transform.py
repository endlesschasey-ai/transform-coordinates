#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åæ ‡æ•°æ®å¼‚æ­¥è½¬æ¢è„šæœ¬

åŠŸèƒ½è¯´æ˜ï¼š
1. å°†å®½æ ¼å¼çš„ç”¨æˆ·åæ ‡æ•°æ®è½¬æ¢ä¸ºé•¿æ ¼å¼
2. ä½¿ç”¨å¼‚æ­¥æ–¹å¼å°†è‹±å›½å›½å®¶ç½‘æ ¼åæ ‡ (EPSG:27700) è½¬æ¢ä¸º WGS84 ç»çº¬åº¦åæ ‡ (EPSG:4326)
3. ä» .env æ–‡ä»¶è¯»å– API å¯†é’¥

ä½œè€…: Claude Code
æ—¥æœŸ: 2025
"""

import pandas as pd
import asyncio
import aiohttp
import os
from datetime import datetime
from typing import Tuple, Optional, List, Dict
from pathlib import Path
import logging
from dotenv import load_dotenv
from collections import defaultdict

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class APIKeyManager:
    """API å¯†é’¥ç®¡ç†å™¨ - æ”¯æŒå¤šä¸ª API KEY å¹¶è‡ªåŠ¨åˆ‡æ¢"""

    def __init__(self, api_keys: List[str]):
        """
        åˆå§‹åŒ– API å¯†é’¥ç®¡ç†å™¨

        å‚æ•°:
            api_keys: API å¯†é’¥åˆ—è¡¨
        """
        if not api_keys:
            raise ValueError("è‡³å°‘éœ€è¦æä¾›ä¸€ä¸ª API KEY")

        self.api_keys = api_keys
        self.current_index = 0
        self.stats = defaultdict(lambda: {
            'requests': 0,
            'success': 0,
            'rate_limit': 0,
            'errors': 0
        })
        logger.info(f"âœ… å·²åŠ è½½ {len(api_keys)} ä¸ª API KEY")

    def get_current_key(self) -> str:
        """è·å–å½“å‰ä½¿ç”¨çš„ API KEY"""
        return self.api_keys[self.current_index]

    def switch_to_next_key(self) -> bool:
        """
        åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª API KEY

        è¿”å›:
            æ˜¯å¦æˆåŠŸåˆ‡æ¢ï¼ˆFalse è¡¨ç¤ºå·²ç»æ˜¯æœ€åä¸€ä¸ª KEYï¼‰
        """
        if self.current_index < len(self.api_keys) - 1:
            old_index = self.current_index
            self.current_index += 1
            logger.warning(f"ğŸ”„ åˆ‡æ¢ API KEY: [{old_index}] -> [{self.current_index}]")
            return True
        else:
            logger.error(f"âš ï¸ æ‰€æœ‰ {len(self.api_keys)} ä¸ª API KEY éƒ½å·²è¾¾åˆ°é€Ÿç‡é™åˆ¶!")
            return False

    def record_request(self, key: str):
        """è®°å½•è¯·æ±‚"""
        self.stats[key]['requests'] += 1

    def record_success(self, key: str):
        """è®°å½•æˆåŠŸ"""
        self.stats[key]['success'] += 1

    def record_rate_limit(self, key: str):
        """è®°å½•é€Ÿç‡é™åˆ¶"""
        self.stats[key]['rate_limit'] += 1

    def record_error(self, key: str):
        """è®°å½•é”™è¯¯"""
        self.stats[key]['errors'] += 1

    def print_stats(self):
        """æ‰“å°ä½¿ç”¨ç»Ÿè®¡"""
        logger.info("\n=== ğŸ“Š API KEY ä½¿ç”¨ç»Ÿè®¡ ===")
        for idx, key in enumerate(self.api_keys):
            stats = self.stats[key]
            key_preview = f"{key[:10]}...{key[-4:]}" if len(key) > 14 else key
            logger.info(f"KEY [{idx}] ({key_preview}):")
            logger.info(f"  æ€»è¯·æ±‚: {stats['requests']}")
            logger.info(f"  æˆåŠŸ: {stats['success']}")
            logger.info(f"  é€Ÿç‡é™åˆ¶: {stats['rate_limit']}")
            logger.info(f"  å…¶ä»–é”™è¯¯: {stats['errors']}")


class AsyncCoordinateTransformer:
    """å¼‚æ­¥åæ ‡è½¬æ¢å™¨ç±» - ä½¿ç”¨ MapTiler API è¿›è¡Œåæ ‡ç³»è½¬æ¢"""

    # MapTiler API é…ç½®
    API_BASE_URL = "https://api.maptiler.com/coordinates/transform"
    SOURCE_CRS = 27700  # è‹±å›½å›½å®¶ç½‘æ ¼åæ ‡ç³» EPSGä»£ç 
    TARGET_CRS = 4326   # WGS84 ç»çº¬åº¦åæ ‡ç³» EPSGä»£ç 

    def __init__(self, api_key_manager: APIKeyManager, max_concurrent: int = 10):
        """
        åˆå§‹åŒ–å¼‚æ­¥åæ ‡è½¬æ¢å™¨

        å‚æ•°:
            api_key_manager: API å¯†é’¥ç®¡ç†å™¨
            max_concurrent: æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
        """
        self.api_key_manager = api_key_manager
        self.max_concurrent = max_concurrent
        self.request_count = 0
        self.failed_requests = 0
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.rate_limit_backoff = 1.0  # é€Ÿç‡é™åˆ¶é€€é¿æ—¶é—´ï¼ˆç§’ï¼‰

    async def transform_coordinate(
        self,
        session: aiohttp.ClientSession,
        x: float,
        y: float,
        max_retries: int = 3
    ) -> Tuple[Tuple[float, float], Optional[Tuple[float, float]]]:
        """
        å¼‚æ­¥è½¬æ¢å•ä¸ªåæ ‡ç‚¹ï¼Œæ”¯æŒ API KEY è‡ªåŠ¨åˆ‡æ¢

        å‚æ•°:
            session: aiohttp ä¼šè¯å¯¹è±¡
            x: ä¸œå‘åæ ‡ (Easting)
            y: åŒ—å‘åæ ‡ (Northing)
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé‡åˆ° 429 é”™è¯¯æ—¶ï¼‰

        è¿”å›:
            ((x, y), (lon, lat)) å…ƒç»„ï¼Œå¤±è´¥åˆ™è¿”å› ((x, y), None)
        """
        async with self.semaphore:  # é™åˆ¶å¹¶å‘æ•°
            for retry in range(max_retries):
                try:
                    # è·å–å½“å‰ API KEY
                    current_key = self.api_key_manager.get_current_key()

                    # æ„å»º API è¯·æ±‚ URL
                    url = f"{self.API_BASE_URL}/{x},{y}.json"
                    params = {
                        's_srs': self.SOURCE_CRS,
                        't_srs': self.TARGET_CRS,
                        'key': current_key
                    }

                    # å‘é€å¼‚æ­¥è¯·æ±‚
                    async with session.get(url, params=params, timeout=aiohttp.ClientTimeout(total=10)) as response:
                        self.request_count += 1
                        self.api_key_manager.record_request(current_key)

                        if response.status == 200:
                            data = await response.json()
                            # API è¿”å›æ ¼å¼: {"results": [{"x": lon, "y": lat}]}
                            if 'results' in data and len(data['results']) > 0:
                                result = data['results'][0]
                                lon = result['x']
                                lat = result['y']
                                self.api_key_manager.record_success(current_key)
                                logger.debug(f"âœ“ ({x}, {y}) -> ({lon:.6f}, {lat:.6f})")
                                return ((x, y), (lon, lat))
                            else:
                                logger.warning(f"âš  Invalid API response for ({x}, {y})")
                                self.api_key_manager.record_error(current_key)
                                self.failed_requests += 1
                                return ((x, y), None)

                        elif response.status == 429:
                            # é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥
                            self.api_key_manager.record_rate_limit(current_key)

                            # é¦–æ¬¡æˆ–å‰å‡ æ¬¡é‡è¯•ï¼šç­‰å¾…åé‡è¯•ï¼ˆä¸åˆ‡æ¢ KEYï¼‰
                            if retry < max_retries - 1:
                                wait_time = self.rate_limit_backoff * (2 ** retry)  # æŒ‡æ•°é€€é¿
                                logger.warning(f"âš  é€Ÿç‡é™åˆ¶ (429) for ({x}, {y})ï¼Œç­‰å¾… {wait_time:.1f}s åé‡è¯• ({retry + 1}/{max_retries})")
                                await asyncio.sleep(wait_time)
                                continue  # é‡è¯•è¯·æ±‚
                            else:
                                # å¤šæ¬¡é‡è¯•åä»ç„¶ 429ï¼Œå°è¯•åˆ‡æ¢ API KEY
                                logger.warning(f"âš  æŒç»­é€Ÿç‡é™åˆ¶ (429) for ({x}, {y})ï¼Œå°è¯•åˆ‡æ¢ API KEY")
                                if self.api_key_manager.switch_to_next_key():
                                    logger.info(f"ğŸ”„ åˆ‡æ¢åˆ°æ–°çš„ API KEY å¹¶é‡è¯•åæ ‡ ({x}, {y})")
                                    await asyncio.sleep(1.0)  # åˆ‡æ¢åç­‰å¾…
                                    continue  # é‡è¯•è¯·æ±‚
                                else:
                                    # æ‰€æœ‰ API KEY éƒ½å·²è¾¾åˆ°é™åˆ¶
                                    logger.error(f"âŒ æ‰€æœ‰ API KEY éƒ½å·²è¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼Œåæ ‡ ({x}, {y}) è½¬æ¢å¤±è´¥")
                                    self.failed_requests += 1
                                    return ((x, y), None)

                        else:
                            logger.error(f"âœ— API status {response.status} for ({x}, {y})")
                            self.api_key_manager.record_error(current_key)
                            self.failed_requests += 1
                            return ((x, y), None)

                except asyncio.TimeoutError:
                    logger.error(f"â± Timeout for ({x}, {y})")
                    current_key = self.api_key_manager.get_current_key()
                    self.api_key_manager.record_error(current_key)
                    self.failed_requests += 1
                    return ((x, y), None)
                except Exception as e:
                    logger.error(f"âŒ Error for ({x}, {y}): {str(e)}")
                    current_key = self.api_key_manager.get_current_key()
                    self.api_key_manager.record_error(current_key)
                    self.failed_requests += 1
                    return ((x, y), None)

            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
            return ((x, y), None)

    async def transform_batch(
        self,
        coordinates_list: List[Tuple[float, float]]
    ) -> Dict[Tuple[float, float], Tuple[float, float]]:
        """
        å¼‚æ­¥æ‰¹é‡è½¬æ¢åæ ‡

        å‚æ•°:
            coordinates_list: åæ ‡åˆ—è¡¨ [(x1, y1), (x2, y2), ...]

        è¿”å›:
            åæ ‡æ˜ å°„å­—å…¸ {(x, y): (lon, lat), ...}
        """
        total = len(coordinates_list)
        logger.info(f"ğŸš€ å¼€å§‹å¼‚æ­¥æ‰¹é‡è½¬æ¢ {total} ä¸ªåæ ‡ç‚¹ (å¹¶å‘æ•°: {self.max_concurrent})...")

        # åˆ›å»ºå¼‚æ­¥ HTTP ä¼šè¯
        async with aiohttp.ClientSession() as session:
            # åˆ›å»ºæ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
            tasks = [
                self.transform_coordinate(session, x, y)
                for x, y in coordinates_list
            ]

            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡å¹¶æ˜¾ç¤ºè¿›åº¦
            results = []
            batch_size = 100
            for i in range(0, len(tasks), batch_size):
                batch = tasks[i:i + batch_size]
                batch_results = await asyncio.gather(*batch)
                results.extend(batch_results)

                # æ˜¾ç¤ºè¿›åº¦
                progress = min(i + batch_size, total)
                logger.info(f"ğŸ“Š è¿›åº¦: {progress}/{total} ({progress/total*100:.1f}%)")

        # æ„å»ºåæ ‡æ˜ å°„å­—å…¸
        coord_map = {}
        for (x, y), result in results:
            if result:
                coord_map[(x, y)] = result

        success_count = len(coord_map)
        success_rate = success_count / total * 100 if total > 0 else 0
        logger.info(f"âœ… æ‰¹é‡è½¬æ¢å®Œæˆ! æˆåŠŸ: {success_count}/{total} ({success_rate:.2f}%), å¤±è´¥: {self.failed_requests}")

        # æ‰“å° API KEY ä½¿ç”¨ç»Ÿè®¡
        self.api_key_manager.print_stats()

        return coord_map


async def transform_data_async(
    input_file: str = '../data.csv',
    output_file: str = '../transformed_data.csv',
    api_keys: Optional[List[str]] = None,
    convert_to_latlon: bool = False,
    max_concurrent: int = 10
) -> pd.DataFrame:
    """
    å¼‚æ­¥è½¬æ¢åæ ‡æ•°æ®ä¸»å‡½æ•°

    å‚æ•°:
        input_file: è¾“å…¥ CSV æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡º CSV æ–‡ä»¶è·¯å¾„
        api_keys: MapTiler API å¯†é’¥åˆ—è¡¨ï¼ˆæ”¯æŒå¤šä¸ª KEY è‡ªåŠ¨åˆ‡æ¢ï¼‰
        convert_to_latlon: æ˜¯å¦è½¬æ¢ä¸ºç»çº¬åº¦åæ ‡
        max_concurrent: æœ€å¤§å¹¶å‘è¯·æ±‚æ•°

    è¿”å›:
        è½¬æ¢åçš„ DataFrame
    """
    # ========== ç¬¬ä¸€æ­¥ï¼šè¯»å–åŸå§‹æ•°æ® ==========
    logger.info(f"ğŸ“‚ æ­£åœ¨è¯»å–æ–‡ä»¶: {input_file}")
    df = pd.read_csv(input_file, low_memory=False)
    logger.info(f"âœ“ å…±è¯»å– {len(df)} æ¡ç”¨æˆ·æ•°æ®")

    # ========== ç¬¬äºŒæ­¥ï¼šå®½æ ¼å¼è½¬é•¿æ ¼å¼ ==========
    logger.info("ğŸ”„ å¼€å§‹è½¬æ¢æ•°æ®æ ¼å¼ï¼ˆå®½æ ¼å¼ -> é•¿æ ¼å¼ï¼‰...")
    transformed_rows = []

    # éå†æ¯ä¸ªç”¨æˆ·
    for row_idx, row in df.iterrows():
        p_id = row['id']  # ç”¨æˆ·ID

        # æŸ¥æ‰¾æ‰€æœ‰æ•°æ®ç‚¹ï¼ˆa0, a1, a2, ...ï¼‰
        for col in df.columns:
            if col.startswith('p32220_a'):
                # æå–æ•°æ®ç‚¹ç¼–å·ï¼ˆå¦‚ 'a0', 'a1'ï¼‰
                a_id = col.split('_')[1]

                # è·å–å¯¹åº”çš„æ—¶é—´ã€xã€y åˆ—
                time_col = f'p32220_{a_id}'
                x_col = f'p32223_{a_id}'
                y_col = f'p32224_{a_id}'

                time_value = row[time_col]
                x_value = row[x_col]
                y_value = row[y_col]

                # è·³è¿‡ç©ºå€¼
                if pd.isna(time_value) or pd.isna(x_value) or pd.isna(y_value):
                    continue

                # è§£ææ—¶é—´å­—æ®µ
                try:
                    date_obj = datetime.strptime(str(time_value), '%Y/%m/%d')
                    year = date_obj.year
                    month = date_obj.month
                    day = date_obj.day
                except Exception:
                    logger.warning(f"âš  æ— æ³•è§£ææ—¶é—´ '{time_value}' (ç”¨æˆ·ID={p_id}, æ•°æ®ç‚¹={a_id})")
                    continue

                # æ·»åŠ è½¬æ¢åçš„è®°å½•
                transformed_rows.append({
                    'p_id': p_id,
                    'a_id': a_id,
                    'year': year,
                    'month': month,
                    'day': day,
                    'x': int(x_value),
                    'y': int(y_value)
                })

        # æ˜¾ç¤ºè¿›åº¦
        if (row_idx + 1) % 10000 == 0:
            logger.info(f"â³ å·²å¤„ç† {row_idx + 1}/{len(df)} ä¸ªç”¨æˆ·...")

    # åˆ›å»ºè½¬æ¢åçš„ DataFrame
    transformed_df = pd.DataFrame(transformed_rows)
    logger.info(f"âœ… æ ¼å¼è½¬æ¢å®Œæˆ! ç”Ÿæˆ {len(transformed_df)} æ¡è®°å½•")

    # ========== ç¬¬ä¸‰æ­¥ï¼šå¼‚æ­¥åæ ‡ç³»è½¬æ¢ï¼ˆå¯é€‰ï¼‰==========
    if convert_to_latlon:
        if not api_keys or len(api_keys) == 0:
            logger.error("âŒ é”™è¯¯: éœ€è¦æä¾› MapTiler API å¯†é’¥æ¥è½¬æ¢åæ ‡ç³»")
            logger.info("ğŸ’¡ è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® MAPTILER_API_KEY (æ”¯æŒå¤šä¸ª KEYï¼Œç”¨é€—å·åˆ†éš”)")
            raise ValueError("API key is required for coordinate transformation")

        logger.info("ğŸŒ å¼€å§‹å¼‚æ­¥è½¬æ¢åæ ‡ç³» (EPSG:27700 -> EPSG:4326)...")

        # åˆ›å»º API å¯†é’¥ç®¡ç†å™¨
        api_key_manager = APIKeyManager(api_keys)

        # åˆå§‹åŒ–å¼‚æ­¥åæ ‡è½¬æ¢å™¨
        transformer = AsyncCoordinateTransformer(api_key_manager, max_concurrent=max_concurrent)

        # æå–å”¯ä¸€çš„åæ ‡ç‚¹ï¼ˆé¿å…é‡å¤è½¬æ¢ï¼‰
        unique_coords = transformed_df[['x', 'y']].drop_duplicates()
        logger.info(f"ğŸ” å‘ç° {len(unique_coords)} ä¸ªå”¯ä¸€åæ ‡ç‚¹")

        # å¼‚æ­¥æ‰¹é‡è½¬æ¢
        coords_list = [(row['x'], row['y']) for _, row in unique_coords.iterrows()]
        coord_map = await transformer.transform_batch(coords_list)

        # åº”ç”¨è½¬æ¢ç»“æœ
        logger.info("ğŸ“ æ­£åœ¨åº”ç”¨åæ ‡è½¬æ¢ç»“æœ...")
        transformed_df['longitude'] = None
        transformed_df['latitude'] = None

        for idx, row in transformed_df.iterrows():
            key = (row['x'], row['y'])
            if key in coord_map:
                lon, lat = coord_map[key]
                transformed_df.at[idx, 'longitude'] = lon
                transformed_df.at[idx, 'latitude'] = lat

        # ç»Ÿè®¡è½¬æ¢æˆåŠŸç‡
        success_count = transformed_df['longitude'].notna().sum()
        success_rate = success_count / len(transformed_df) * 100
        logger.info(f"âœ… åæ ‡è½¬æ¢å®Œæˆ! æˆåŠŸç‡: {success_rate:.2f}% ({success_count}/{len(transformed_df)})")

    # ========== ç¬¬å››æ­¥ï¼šä¿å­˜ç»“æœ ==========
    transformed_df.to_csv(output_file, index=False)
    logger.info(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜è‡³: {output_file}")

    # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
    logger.info("\n=== ğŸ“Š æ•°æ®é¢„è§ˆ ===")
    print(transformed_df.head(10))

    # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
    logger.info("\n=== ğŸ“ˆ æ•°æ®ç»Ÿè®¡ ===")
    logger.info(f"æ€»è®°å½•æ•°: {len(transformed_df)}")
    logger.info(f"ç”¨æˆ·æ•°: {transformed_df['p_id'].nunique()}")
    logger.info(f"æ•°æ®ç‚¹åˆ†å¸ƒ:")
    print(transformed_df['a_id'].value_counts().sort_index().head(10))

    return transformed_df


def main():
    """ä¸»å‡½æ•° - è¿è¡Œå¼‚æ­¥è½¬æ¢æµç¨‹"""
    # ========== é…ç½®å‚æ•° ==========
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = Path(__file__).parent
    project_root = script_dir.parent

    INPUT_FILE = project_root / 'data/origin_data.csv'
    OUTPUT_FILE = project_root / 'data/transformed_data.csv'

    # ä»ç¯å¢ƒå˜é‡è¯»å– API å¯†é’¥ï¼ˆæ”¯æŒå¤šä¸ª KEYï¼Œç”¨é€—å·åˆ†éš”ï¼‰
    maptiler_api_key_str = os.getenv('MAPTILER_API_KEY', '')

    # è§£æ API KEY åˆ—è¡¨
    api_keys = []
    if maptiler_api_key_str:
        # æŒ‰é€—å·åˆ†éš”ï¼Œå¹¶å»é™¤ç©ºæ ¼
        api_keys = [key.strip() for key in maptiler_api_key_str.split(',') if key.strip()]

    if not api_keys:
        logger.warning("âš  æœªæ‰¾åˆ° MAPTILER_API_KEY ç¯å¢ƒå˜é‡")
        logger.info("ğŸ’¡ å°†åªæ‰§è¡Œæ ¼å¼è½¬æ¢ï¼Œä¸è¿›è¡Œåæ ‡ç³»è½¬æ¢")
        logger.info("ğŸ’¡ å¦‚éœ€è½¬æ¢åæ ‡ç³»ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® MAPTILER_API_KEY")
        logger.info("ğŸ’¡ æ”¯æŒå¤šä¸ª API KEYï¼ˆç”¨é€—å·åˆ†éš”ï¼‰: KEY1,KEY2,KEY3")
    else:
        logger.info(f"âœ… å·²ä»ç¯å¢ƒå˜é‡åŠ è½½ {len(api_keys)} ä¸ª API KEY")

    # æ˜¯å¦è½¬æ¢ä¸ºç»çº¬åº¦åæ ‡
    CONVERT_TO_LATLON = len(api_keys) > 0  # æœ‰ API KEY åˆ™è‡ªåŠ¨å¯ç”¨

    # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
    MAX_CONCURRENT = 10

    # ========== æ‰§è¡Œå¼‚æ­¥è½¬æ¢ ==========
    logger.info("=" * 60)
    logger.info("ğŸš€ å¯åŠ¨åæ ‡æ•°æ®å¼‚æ­¥è½¬æ¢ç¨‹åº")
    logger.info("=" * 60)

    try:
        # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
        asyncio.run(
            transform_data_async(
                input_file=str(INPUT_FILE),
                output_file=str(OUTPUT_FILE),
                api_keys=api_keys,
                convert_to_latlon=CONVERT_TO_LATLON,
                max_concurrent=MAX_CONCURRENT
            )
        )
        logger.info("\n" + "=" * 60)
        logger.info("âœ… æ‰€æœ‰è½¬æ¢ä»»åŠ¡å®Œæˆ!")
        logger.info("=" * 60)
    except Exception as e:
        logger.error(f"\nâŒ è½¬æ¢å¤±è´¥: {str(e)}")
        raise


if __name__ == '__main__':
    main()
